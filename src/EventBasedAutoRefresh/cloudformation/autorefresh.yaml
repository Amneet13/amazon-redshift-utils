Parameters:
  LambdaLogRetention:
    Type: Number
    Default: 90
    MinValue: 1
    MaxValue: 3653
    Description: Number of days to retain logs from the Lambda function. Default is 90 days.
  LambdaExecutionTimeout:
    Type: Number
    Default: 300
    MinValue: 15
    MaxValue: 900
    Description: Number of seconds before Lambda function times out. Default is 300 seconds. Range is 15 to 900 seconds.
  RefreshDelaySecs:
    Type: Number
    Default: 5
    MinValue: 2
    MaxValue: 900
    Description: Number of seconds to delay after finishing a refresh before triggering a new refresh. Default is 5 seconds. Range is 2 to 900 seconds.
  ClusterDBUser:
    Type: String
    Default: "stream_mv_user"
    Description: Username to use for connecting to Redshift cluster. Default is stream_mv_user. You can set to * if you want to connect as any database user.
  LambdaBatchSize:
    Type: Number
    Default: 5
    MinValue: 1
    MaxValue: 30
    Description: Number of items for Lambda function to batch from SQS before processing. Default is 5. Range is 1 to 30.

Resources: 
  MVRefreshLambdaLogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName:
        Fn::Sub:
          - "/aws/lambda/${lambdafunctionname}"
          - lambdafunctionname: 
              Ref: MVRefreshLambda
      RetentionInDays: 
        Ref: LambdaLogRetention
    DependsOn: MVRefreshLambda

  MVRefreshSQSQueue:
    Type: AWS::SQS::Queue
    Properties:
      DelaySeconds: 
        Ref: RefreshDelaySecs
      VisibilityTimeout:
        Ref: LambdaExecutionTimeout

  MVRefreshSQSPolicy:
    Type: AWS::SQS::QueuePolicy
    Properties: 
      PolicyDocument: 
        Statement: 
          - Action: 
              - "SQS:SendMessage"
            Effect: "Allow"
            Resource:
              - Fn::GetAtt:
                - MVRefreshSQSQueue
                - Arn
            Principal:  
              Service: "events.amazonaws.com"
      Queues:
        - Ref: MVRefreshSQSQueue


  MVRefreshEventRule:
    Type: AWS::Events::Rule
    Properties:
      EventPattern: 
        source: 
          - "aws.redshift-data"
        detail-type: 
          - "Redshift Data Statement Status Change"
      State: ENABLED
      Targets:
        - 
          Arn:
            Fn::GetAtt:
              - MVRefreshSQSQueue
              - Arn
          Id: MVRefreshLambdaTarget

  MVRefreshSNS:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: MVRefreshSNS-notifications

  MVRefreshDDBTable:
  # mvname autorefresh clusterid database_name sql username
    Type: AWS::DynamoDB::Table
    Properties: 
      AttributeDefinitions: 
        - 
          AttributeName: "mvname"
          AttributeType: "S"
        -
          AttributeName: "clusterid"
          AttributeType: "S"
      BillingMode: PAY_PER_REQUEST
      KeySchema: 
        - 
          AttributeName: "mvname"
          KeyType: HASH
        -
          AttributeName: "clusterid"
          KeyType: RANGE
      StreamSpecification: 
        StreamViewType: NEW_AND_OLD_IMAGES

  MVRefreshLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Statement:
          - Action: sts:AssumeRole
            Effect: Allow
            Principal:
              Service: "lambda.amazonaws.com"
        Version: "2012-10-17"

  MVRefreshLambdaPolicy:
    Type: AWS::IAM::Policy
    Properties:
      PolicyDocument:
        Statement:
          - Action:
              - redshift:GetClusterCredentials
            Effect: Allow
            Resource:
              - Fn::Sub: "arn:aws:redshift:${AWS::Region}:${AWS::AccountId}:dbuser:*/${ClusterDBUser}"
              - Fn::Sub: "arn:aws:redshift:${AWS::Region}:${AWS::AccountId}:dbname:*"
          - Action:
              - redshift-data:ExecuteStatement
              - redshift-data:DescribeStatement
              - redshift-data:GetStatementResult
            Effect: Allow
            Resource: "*" 
          - Action:
              - dynamodb:GetItem
              - dynamodb:UpdateItem
            Effect: Allow
            Resource:
              - Fn::GetAtt:
                - MVRefreshDDBTable
                - Arn
          - Action:
              - sqs:DeleteMessage
              - sqs:ReceiveMessage
              - sqs:GetQueueAttributes
            Effect: Allow
            Resource:
              - Fn::GetAtt:
                - MVRefreshSQSQueue
                - Arn
          - Action:
              - sns:Publish
            Effect: Allow
            Resource:
              - Ref: MVRefreshSNS
          - Action:
              - logs:CreateLogStream
              - logs:PutLogEvents
            Effect: Allow
            Resource:
              - Fn::GetAtt:
                - MVRefreshLambdaLogGroup
                - Arn
          - Action:
              - firehose:* 
            Effect: Allow
            Resource: 
              - "arn:aws:firehose:us-east-1:757848091413:deliverystream/data_api"
              - "arn:aws:firehose:us-east-1:757848091413:deliverystream/sqslogs"
          - Action:
              - dynamodb:ListStreams
            Effect: Allow
            Resource:
              - Fn::GetAtt:
                - MVRefreshDDBTable
                - StreamArn 
          - Action:
              - dynamodb:GetRecords
              - dynamodb:GetShardIterator
              - dynamodb:DescribeStream
            Effect: Allow
            Resource: 
              - Fn::GetAtt:
                - MVRefreshDDBTable
                - StreamArn
        Version: "2012-10-17"
      PolicyName: MVRefreshLambdaRolePolicy
      Roles:
        - Ref: MVRefreshLambdaRole

  MVLambdaSQSTrigger:
    Type: AWS::Lambda::EventSourceMapping
    Properties: 
      BatchSize: 
        Ref: LambdaBatchSize
      Enabled: True
      EventSourceArn: 
        Fn::GetAtt:
          - MVRefreshSQSQueue
          - Arn
      FunctionName: 
        Fn::GetAtt:
          - MVRefreshLambda
          - Arn
    DependsOn: MVRefreshLambdaPolicy
  
  MVLambdaDynamodbStreamsTrigger:
    Type: AWS::Lambda::EventSourceMapping
    Properties:
      BatchSize: 
        Ref: LambdaBatchSize
      Enabled: True
      EventSourceArn:
        Fn::GetAtt:
          - MVRefreshDDBTable
          - StreamArn
      FunctionName:
        Fn::GetAtt:
          - MVRefreshLambda 
          - Arn
      StartingPosition: LATEST
    DependsOn: MVRefreshLambdaPolicy

  MVRefreshLambda:
    Type: AWS::Lambda::Function
    Properties:
      Code: 
        ZipFile: |
          import json
          import logging
          import boto3
          import os
          import time


          logger = logging.getLogger()
          logger.setLevel(logging.INFO)
          rsapi = boto3.client('redshift-data')
          kfhose = boto3.client('firehose')
          snsclient = boto3.client('sns')
          dynamodb = boto3.resource('dynamodb')
          tablename = os.environ['DDBTABLE']
          ddbtable = dynamodb.Table(tablename)
          snstopic = os.getenv('SNSTOPIC',None)
          maxfailures = 5


          def check_refresh_status(ddbitem):
            checksql = f"select query from stv_recents where status <> 'Done' and db_name = '{ddbitem['database_name']}' and user_name='IAM:{ddbitem['username']}' and query = '{ddbitem['sql']}'"
            logger.debug(checksql)
            response = rsapi.execute_statement(ClusterIdentifier=ddbitem['clusterid'], Database=ddbitem['database_name'], DbUser=ddbitem['username'], 
                                                Sql=checksql, StatementName=f"Check {ddbitem['mvname']} refresh status")
            logger.info(json.dumps(response, default=str))                             
            queryid = response['Id']
            status = None         
            while status not in ['FAILED','FINISHED']:
              status = rsapi.describe_statement(Id=queryid)['Status']
              logger.debug(status)
              time.sleep(5)
            numrows = rsapi.get_statement_result(Id=queryid)['TotalNumRows']
            logger.info(f"Check status query: {queryid} \nNumrows: {numrows} \n{json.dumps(response, default=str)}")
            return(numrows)


          def execute_statement(ddbitem):
            if ddbitem:
              if ddbitem['autorefresh']:
                response = rsapi.execute_statement(ClusterIdentifier=ddbitem['clusterid'], Database=ddbitem['database_name'], DbUser=ddbitem['username'], 
                                                    Sql=ddbitem['sql'], StatementName=ddbitem['mvname'], WithEvent=True)
                logger.info(f"Redshift api response: {json.dumps(response, default=str)}")
                logger.info(f"Sent query to {ddbitem['clusterid']} to refresh {ddbitem['mvname']} in database {ddbitem['database_name']}")
              else:
                msg = f"Auto Refresh is disabled on MV {ddbitem['mvname']} in database {ddbitem['database_name']} for cluster {ddbitem['clusterid']}"
                logger.info(f"{msg} Skipping...")
                if snstopic:
                  snsclient.publish(TopicArn=snstopic,
                                    Message=msg, Subject=f"{ddbitem['mvname']} MV Refresh on {ddbitem['clusterid']}")
            else:
              logger.info("Item not found!")
                      
              
          def trigger_first_refresh(record):
            try:
              eventName = record['eventName']
              logger.info(f"Event type is {eventName}...")
              if eventName != 'REMOVE':
                if eventName == 'MODIFY':
                  oldimage = record['dynamodb']['OldImage']
                  prevautorefresh = oldimage['autorefresh']['BOOL']
                else:
                  prevautorefresh = None
                newimage = record['dynamodb']['NewImage']
                ddbitem = {'failure_cnt': newimage['failure_cnt']['N'], 'clusterid': newimage['clusterid']['S']
                        , 'database_name': newimage['database_name']['S'], 'autorefresh': newimage['autorefresh']['BOOL']
                        , 'username': newimage['username']['S'], 'mvname': newimage['mvname']['S']
                        , 'sql': newimage['sql']['S'] }
                logger.info(f"Extracted {ddbitem['mvname']} attributes from dynamodb event: {ddbitem}")
                if (ddbitem['autorefresh'] and not prevautorefresh) or eventName == 'INSERT':
                  msg = f"Starting Auto Refresh on MV {ddbitem['mvname']} in database {ddbitem['database_name']} for cluster {ddbitem['clusterid']}"
                  logger.info(msg)
                  if snstopic:
                    snsclient.publish(TopicArn=snstopic, Message=msg, Subject=f"{ddbitem['mvname']} MV Refresh on {ddbitem['clusterid']}")
                  execute_statement(ddbitem)
                elif ddbitem['autorefresh'] is False:
                  execute_statement(ddbitem)
            except KeyError as e:
              logger.error(f"Key Error: {e} is missing in dynamodb response") 
            except Exception as e:
              logger.exception(e) 


          def trigger_next_refresh(record):
            msgbody = json.loads(record['body'])
            caller_function = msgbody['detail']['principal'].split('/')[-1]
            logger.info(json.dumps(msgbody, default=str))
            mvname = msgbody['detail']['statementName']
            clusterid = msgbody['resources'][0].split(':')[-1]
            logger.info(f"MV: {mvname} Clusterid: {clusterid}")
            ddbresponse = ddbtable.get_item(Key={'mvname': mvname, 'clusterid': clusterid}, ConsistentRead=True)
            logger.debug(f"Get item DDB response: {json.dumps(ddbresponse, default=str)}")
            ddbitem = ddbresponse['Item']
            msgsubject = f"{mvname} MV Refresh on {clusterid}"
            # Check and ensure that message received was generated by this Lambda function
            if caller_function == record['function_name'] and ddbitem:
              dbname = ddbitem['database_name']
              numrows = check_refresh_status(ddbitem)
              if numrows == 0:
                dbname = ddbitem['database_name']
                failure_cnt = int(ddbitem['failure_cnt'])
                if msgbody['detail']['state'] == 'FINISHED': 
                  execute_statement(ddbitem)
                  if failure_cnt > 0:
                    logger.info(f"Refresh succeeded. Resetting failure_cnt for MV {mvname} in cluster {clusterid} to 0.")
                    dynamodb.Table(tablename).update_item(Key={'mvname': mvname, 'clusterid': clusterid}, UpdateExpression="set failure_cnt = :val"
                                                          ,ExpressionAttributeValues={':val': 0}, ReturnValues="UPDATED_NEW")
                else:
                  failure_cnt += 1
                  msg = f"Auto Refresh on MV {mvname} in database {dbname} for cluster {clusterid} failed {failure_cnt} times. "
                  if failure_cnt < maxfailures:
                    dynamodb.Table(tablename).update_item(Key={'mvname': mvname, 'clusterid': clusterid}, UpdateExpression="set failure_cnt = :val"
                                                          ,ExpressionAttributeValues={':val': failure_cnt}, ReturnValues="UPDATED_NEW")
                    errormsg = f"{msg}. Retrying refresh...\n {msgbody}"
                    logger.info(errormsg)
                    execute_statement(ddbitem)
                    if snstopic:
                      snsclient.publish(TopicArn=snstopic, Message=errormsg, Subject=msgsubject)
                  else:
                    dynamodb.Table(tablename).update_item(Key={'mvname': mvname, 'clusterid': clusterid}, UpdateExpression="set autorefresh = :val, failure_cnt = :cnt"
                                                            ,ExpressionAttributeValues={':val': False, ':cnt': failure_cnt}, ReturnValues="UPDATED_NEW")
                    errormsg = msg + f"Autorefresh disabled. Check the materialized view on your Redshift cluster.\n {msgbody}"
                    logger.info(errormsg)
                    if snstopic:
                      snsclient.publish(TopicArn=snstopic, Message=errormsg, Subject=msgsubject)
              else:
                msg = f"There is at least one refresh already running on MV {mvname} in database {dbname} on cluster {clusterid}. Refresh count: {numrows}"
                logger.info(msg)
                if snstopic:
                  snsclient.publish(TopicArn=snstopic, Message=msg, Subject=msgsubject)


          def lambda_handler(event, context):
            logger.debug(json.dumps(event, default=str))
            for record in event['Records']:
              logger.info(json.dumps(record, default=str))
              eventsource = record['eventSource'] 
              if eventsource == 'aws:dynamodb':
                logger.info('Eventsource is dynamodb...')
                trigger_first_refresh(record)
              elif eventsource == 'aws:sqs':
                logger.info('Eventsource is sqs...')
                record['function_name'] = context.function_name
                trigger_next_refresh(record)
              else:
                logger.info(f"No handling for events from {eventsource}!")
      Environment:
        Variables:
          DDBTABLE: 
            Ref: MVRefreshDDBTable
          SNSTOPIC:
            Ref: MVRefreshSNS
      Handler: index.lambda_handler
      Role: 
        Fn::GetAtt:
          - MVRefreshLambdaRole
          - Arn 
      Runtime: "python3.9"
      Timeout:
        Ref: LambdaExecutionTimeout
